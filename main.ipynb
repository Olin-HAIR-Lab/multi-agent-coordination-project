{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Multi-Agent Coordination\n",
    "\n",
    "##### Project Definition:\n",
    "* Given a defined task list (including pick and drop locations for N deliveries), operate M Crazyflie agents to complete the defined task as quickly as possible\n",
    "\n",
    "<img src=\"./media/world-file.PNG\"  width=\"50%\" height=\"20%\">\n",
    "\n",
    "* Here, number of tasks (N) is 4, and number of Crazyflie agents (M) is 3.\n",
    "* See image below for a graphical representation of the task list (specific information is provided in the `config.yaml` file)\n",
    "\n",
    "<img src=\"./media/robosys-module-3-project.PNG\"  width=\"50%\" height=\"30%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "##### What to Do:\n",
    "\n",
    "1. Review and understand task and agent definitions in STEP 1 below\n",
    "\n",
    "2. Review and understand the *Multi-agent task assignment* implementation in STEP 2 below\n",
    "\n",
    "3. Implement a *Multi-agent path finding* algorithm (STEP 3 below) that computes a conflict-free paths/trajectory for each agent\n",
    "\n",
    "4. Integrate your trajectory-following algorithm from Module 2 (STEP 4 below)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: Define the task list, agent list and environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimensions': {'x_max': 21, 'x_min': -9, 'y_max': 11, 'y_min': -9}, 'obstacles': [(5, -8), (4, -6), (9, -10), (9, -7), (0, -10), (8, -9), (10, -6), (11, -10), (0, -7), (2, -10), (8, -6), (1, -6), (10, -9), (2, -7), (1, -9), (11, -7), (7, -8), (6, -10), (6, -7), (4, -10), (12, -9), (4, -7), (3, -9), (12, -6), (5, -6), (3, -6), (5, -9), (8, -10), (8, -7), (10, -10), (9, -8), (2, -8), (1, -10), (0, -8), (10, -7), (11, -8), (1, -7), (6, -8), (7, -9), (7, -6), (12, -10), (12, -7), (3, -10), (3, -7), (5, -10), (4, -8), (5, -7), (8, -8), (9, -9), (10, -8), (9, -6), (0, -9), (11, -9), (1, -8), (0, -6), (2, -9), (11, -6), (2, -6), (7, -10), (6, -6), (7, -7), (6, -9), (12, -8), (3, -8), (4, -9)]}\n",
      "Starting up the notebook for the Multi-Agent Coordination module... \n",
      "\n",
      "Number of Agents: [3] -> ['CF7', 'CF8', 'CF9']\n",
      "Use Hardware: [False]\n",
      "Time Delta (dt): [0.25]\n"
     ]
    }
   ],
   "source": [
    "from scripts.utils import Task, Position, State, VelCommand, define_env\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "# load configuration file from YAML file\n",
    "with open('./scripts/config_new.yaml', 'r') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "use_hardware = config['use_hardware']\n",
    "agent_init = config['agent_init']\n",
    "colors = config['agent_colors']\n",
    "time_delta = config['time_delta']\n",
    "# env = config['map']\n",
    "env = define_env(config['map']) # update to process simplified map definition\n",
    "env_simplified = config['map'].copy()\n",
    "num_agents = len(agent_init)\n",
    "\n",
    "\n",
    "print('Starting up the notebook for the Multi-Agent Coordination module... \\n')\n",
    "print(f'Number of Agents: [{num_agents}] -> {[agent_init[i][0] for i in range(len(agent_init))]}')\n",
    "print(f'Use Hardware: [{use_hardware}]')\n",
    "print(f'Time Delta (dt): [{time_delta}]')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.A. Define Task List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Task List\n",
      "-----------------------\n",
      "Task T0: P1 -> D1\n",
      "Task T1: P2 -> D2\n",
      "Task T2: P3 -> D2\n",
      "Task T3: P4 -> D1\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# create the task list\n",
    "task_list = dict()\n",
    "pick_locations = config['pick_loc']\n",
    "drop_locations = config['drop_loc']\n",
    "\n",
    "print('-----------------------')\n",
    "print('Task List')\n",
    "print('-----------------------')\n",
    "\n",
    "for i in range(len(pick_locations)):\n",
    "    t = Task(pick_loc=Position(x=pick_locations[i][1][0], y=pick_locations[i][1][1], z=pick_locations[i][1][2]),\n",
    "             drop_loc=Position(x=drop_locations[i][1][0], y=drop_locations[i][1][1], z=0.0), \n",
    "             pick_id=pick_locations[i][0], \n",
    "             drop_id=drop_locations[i][0], \n",
    "             id='T'+str(i), \n",
    "             priority=i)\n",
    "    task_list[pick_locations[i][0]] = t\n",
    "\n",
    "    print(f'Task {t.id}: {t.pick_id} -> {t.drop_id}')\n",
    "\n",
    "print('-----------------------')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.B. Define Agent List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Agent List (with home position)\n",
      "----------------------------------\n",
      "Agent CF7: (-0.6, 0.9) \n",
      "Agent CF8: (-0.6, 0.3) \n",
      "Agent CF9: (-0.6, -0.3) \n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create the agent list\n",
    "\n",
    "from scripts.Quadrotor import Quadrotor\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Agent List (with home position)')\n",
    "print('----------------------------------')\n",
    "\n",
    "\n",
    "agent_list = dict()\n",
    "for i in range(num_agents):\n",
    "    # define initial state\n",
    "    start = State(x_pos=agent_init[i][1][0], \n",
    "                  y_pos=agent_init[i][1][1])\n",
    "    # define the appropriate URI\n",
    "    uri = 'radio://0/'+agent_init[i][0][2:]+'0/2M/E7E7E7E7E7'\n",
    "    # define agent as Quadrotor\n",
    "    agent = Quadrotor(init_state=start, \n",
    "                      color=colors[i], \n",
    "                      id=agent_init[i][0], \n",
    "                      uri=uri,\n",
    "                      take_off_height=agent_init[i][2], \n",
    "                      hardware_flag=use_hardware,\n",
    "                      dt=time_delta)\n",
    "    agent_list[agent._id] = agent\n",
    "\n",
    "    if use_hardware:\n",
    "        print(f'Agent {agent._id}: {agent_list[agent._id].get_pos().x, agent_list[agent._id].get_pos().y} \\\n",
    "              ---> {uri}')\n",
    "    else:\n",
    "        print(f'Agent {agent._id}: {agent_list[agent._id].get_pos().x, agent_list[agent._id].get_pos().y} ')\n",
    "\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "if use_hardware:\n",
    "    print('\\n !!!!!!!!Please ensure you confirm the Crazyflies are connected to the right radio channels!!!!!!!!')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: Implement Multi-Agent Task Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.A. Define the Ground Constrol System & compute assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.GroundControl import GroundControlSystem\n",
    "\n",
    "# instantiate ground control system object\n",
    "gcs = GroundControlSystem(agent_list=agent_list, \n",
    "                          task_list=task_list,\n",
    "                          env=env)\n",
    "\n",
    "# creates a directed graph based on the agents and task list\n",
    "gcs.set_task_graph(draw=False) # toggle draw True or False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Task Assignment\n",
      "----------------------\n",
      "Agent CF9 : P4 -> D1\n",
      "Agent CF7 : P1 -> D1\n",
      "Agent CF8 : P2 -> D2\n",
      "Agent CF8 : P3 -> D2\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('----------------------')\n",
    "print('Task Assignment')\n",
    "print('----------------------')\n",
    "\n",
    "# create task assignment\n",
    "gcs.create_task_assignment()\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "\n",
    "# observe task assignment\n",
    "task_assignment = gcs.get_task_assignment(draw=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: Implement Multi-Agent Path Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, -8), (4, -6), (9, -10), (9, -7), (0, -10), (8, -9), (10, -6), (11, -10), (0, -7), (2, -10), (8, -6), (1, -6), (10, -9), (2, -7), (1, -9), (11, -7), (7, -8), (6, -10), (6, -7), (4, -10), (12, -9), (4, -7), (3, -9), (12, -6), (5, -6), (3, -6), (5, -9), (8, -10), (8, -7), (10, -10), (9, -8), (2, -8), (1, -10), (0, -8), (10, -7), (11, -8), (1, -7), (6, -8), (7, -9), (7, -6), (12, -10), (12, -7), (3, -10), (3, -7), (5, -10), (4, -8), (5, -7), (8, -8), (9, -9), (10, -8), (9, -6), (0, -9), (11, -9), (1, -8), (0, -6), (2, -9), (11, -6), (2, -6), (7, -10), (6, -6), (7, -7), (6, -9), (12, -8), (3, -8), (4, -9)]\n",
      "(5, -8)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m sim\u001b[39m.\u001b[39madd_agents(agent_list)\n\u001b[0;32m     15\u001b[0m sim\u001b[39m.\u001b[39mset_task_list(task_list)\n\u001b[1;32m---> 16\u001b[0m sim\u001b[39m.\u001b[39;49minit_plot()\n",
      "File \u001b[1;32mc:\\Users\\kmbanisi.MILKYWAY\\Desktop\\summer-research-ws\\multi-agent-coordination-project\\scripts\\_Simulation.py:29\u001b[0m, in \u001b[0;36mSimulation.init_plot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"creates the plotly 2D and 3D plots\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m# 2D plot\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_2D_plot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ply_fig1)\n\u001b[0;32m     30\u001b[0m \u001b[39m# self._ply_fig1.show()\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[39m# 3D plot\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_3D_plot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ply_fig2)\n",
      "File \u001b[1;32mc:\\Users\\kmbanisi.MILKYWAY\\Desktop\\summer-research-ws\\multi-agent-coordination-project\\scripts\\_Simulation.py:97\u001b[0m, in \u001b[0;36mSimulation.create_2D_plot\u001b[1;34m(self, fig)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m obstacle \u001b[39min\u001b[39;00m obstacles:\n\u001b[0;32m     95\u001b[0m     \u001b[39mprint\u001b[39m(obstacle)\n\u001b[0;32m     96\u001b[0m     fig\u001b[39m.\u001b[39madd_shape(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrect\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m---> 97\u001b[0m                     x0\u001b[39m=\u001b[39mobstacle[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m, y0\u001b[39m=\u001b[39mobstacle[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m, x1\u001b[39m=\u001b[39mobstacle[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m, y1\u001b[39m=\u001b[39mobstacle[\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m     98\u001b[0m                     line\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLightSkyBlue\u001b[39m\u001b[39m\"\u001b[39m), fillcolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLightSkyBlue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[39m# plot agent start locations\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agent_list\u001b[39m.\u001b[39mvalues():        \n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from scripts._Simulation import Simulation\n",
    "import plotly.graph_objects as go\n",
    "fig1 = go.Figure()\n",
    "fig2 = go.Figure()\n",
    "\n",
    "fig_animated = go.Figure()\n",
    "fig3d_animated = go.Figure()\n",
    "\n",
    "# sim = Simulation(env=env, fig1=fig1, fig2=fig2)\n",
    "\n",
    "sim = Simulation(env=env_simplified, fig1=fig1, fig2=fig2,\n",
    "                 fig_animated=fig_animated, fig3d_animated=fig3d_animated)\n",
    "\n",
    "sim.add_agents(agent_list)\n",
    "sim.set_task_list(task_list)\n",
    "sim.init_plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.A. Compute collision-free paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, you should implement your multi-agent path finding algorithm...\n",
    "gcs.generate_agent_paths()\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Plotter\n",
    "# sim.init_plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Control Loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 4: Implement the Path planning & collision avoidance algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your functions from Module 2 here\n",
    "\n",
    "def agent_nav(self):\n",
    "    V = VelCommand()\n",
    "    V.vx = 0.2\n",
    "    V.vy = 0.0\n",
    "    V.vz = 0.0\n",
    "    V.v_psi = 0.0\n",
    "    \n",
    "    if self._hardware_flag:\n",
    "        self.velocity_setpoint_hw(V)\n",
    "    else:\n",
    "        self.velocity_setpoint_sim(V)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 5: Run the Main control loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.A. Run a hardware test [If using hardware]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for agent in agent_list.values():\n",
    "#     agent.initialize_agent()\n",
    "\n",
    "\n",
    "# time.sleep(3)\n",
    "\n",
    "\n",
    "# for agent in agent_list.values():\n",
    "#     agent.land()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.B. Run main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lapse = 0\n",
    "flight_duration = 3\n",
    "\n",
    "# initialize and take off all agents\n",
    "for agent in agent_list.values():\n",
    "    agent.initialize_agent()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# while True:\n",
    "while time_lapse < flight_duration: #secs\n",
    "\n",
    "    for agent in agent_list.values():\n",
    "\n",
    "        agent.control_method = agent_nav(agent)\n",
    "        \n",
    "        # print out current position of each agent\n",
    "        x, y, z = agent.get_pos().x, agent.get_pos().y, agent.get_pos().z\n",
    "        print(f'Agent [{agent._id}]: t = {time_lapse} -> [x, y, z] = [{x:0.3f}, {y:0.3f}, {z:0.3f}]')\n",
    "        \n",
    "    print('------------------------------------')    \n",
    "\n",
    "    # keep track of time lapsed\n",
    "    time_lapse += time_delta\n",
    "\n",
    "    time.sleep(time_delta) \n",
    "\n",
    "# land all agents\n",
    "for agent in agent_list.values():\n",
    "    agent.land()\n",
    "\n",
    "# plot the agent trajectory\n",
    "sim.update_plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1f000c4287234902b023eabf8e55dbd1592366d06059d835cf27476eda7405f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
